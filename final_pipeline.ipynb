{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469ef000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Column Name Issues:\n",
      "{\n",
      "  \"missing_columns\": [\n",
      "    \"order_date_(DateOrders)\",\n",
      "    \"Product_Description\"\n",
      "  ],\n",
      "  \"unexpected_columns\": [\n",
      "    \"untracked_feature\",\n",
      "    \"Order_Item_Qty\",\n",
      "    \"Cust_State\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "üîç Row-level Violations (Top 3):\n",
      "[\n",
      "  {\n",
      "    \"row\": 5,\n",
      "    \"problems\": {\n",
      "      \"Sales_per_customer\": {\n",
      "        \"issue\": \"Wrong data type\",\n",
      "        \"value\": \"unknown\",\n",
      "        \"expected_type\": \"numeric\"\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"row\": 6,\n",
      "    \"problems\": {\n",
      "      \"Days_for_shipping_(real)\": {\n",
      "        \"issue\": \"Wrong data type\",\n",
      "        \"value\": \"five\",\n",
      "        \"expected_type\": \"numeric\"\n",
      "      },\n",
      "      \"Order_Item_Product_Price\": {\n",
      "        \"issue\": \"Wrong data type\",\n",
      "        \"value\": \"cheap\",\n",
      "        \"expected_type\": \"numeric\"\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"row\": 7,\n",
      "    \"problems\": {\n",
      "      \"Delivery_Status\": {\n",
      "        \"issue\": \"Invalid category\",\n",
      "        \"value\": \"arriving_soon\",\n",
      "        \"expected\": [\n",
      "          \"Late delivery\",\n",
      "          \"Advance shipping\",\n",
      "          \"Shipping on time\",\n",
      "          \"Shipping canceled\"\n",
      "        ]\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "]\n",
      "\n",
      "‚úÖ Completed firewall check:\n",
      "- Column issues saved to schema_column_issues.json\n",
      "- Row violations saved to genai_firewall_violations.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# Load raw data\n",
    "df = pd.read_csv(r'C:\\Users\\sagni\\Downloads\\GenAI Data Drift Firewall\\GenAI Data Drift Firewall\\data_drift.csv')\n",
    "\n",
    "# Load reference schema\n",
    "with open(\"genai_schema_reference.json\", \"r\") as f:\n",
    "    schema = json.load(f)\n",
    "\n",
    "# Step 1: Column name/schema issues\n",
    "expected_columns = set(schema.keys())\n",
    "actual_columns = set(df.columns)\n",
    "\n",
    "missing_columns = list(expected_columns - actual_columns)\n",
    "unexpected_columns = list(actual_columns - expected_columns)\n",
    "\n",
    "schema_column_issues = {\n",
    "    \"missing_columns\": missing_columns,\n",
    "    \"unexpected_columns\": unexpected_columns\n",
    "}\n",
    "\n",
    "# Save and print column-level issues\n",
    "with open(\"schema_column_issues.json\", \"w\") as f:\n",
    "    json.dump(schema_column_issues, f, indent=2)\n",
    "\n",
    "print(\"‚ö†Ô∏è Column Name Issues:\")\n",
    "print(json.dumps(schema_column_issues, indent=2))\n",
    "\n",
    "# Step 2: Row-level validation (check ALL violations, even if value is missing)\n",
    "available_schema = {col: rules for col, rules in schema.items() if col in df.columns}\n",
    "violations = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    row_issues = {}\n",
    "\n",
    "    for col, rules in available_schema.items():\n",
    "        value = row.get(col, None)\n",
    "\n",
    "        # Always check missing/blank\n",
    "        if pd.isna(value) or (isinstance(value, str) and value.strip() == \"\"):\n",
    "            row_issues[col] = {\n",
    "                \"issue\": \"Missing/blank value\"\n",
    "            }\n",
    "\n",
    "        # Categorical check\n",
    "        if rules[\"type\"] == \"categorical\":\n",
    "            if not isinstance(value, str):\n",
    "                row_issues.setdefault(col, {})[\"issue\"] = \"Wrong data type for categorical\"\n",
    "                row_issues[col][\"value\"] = value\n",
    "                row_issues[col][\"expected_type\"] = \"string\"\n",
    "            elif value not in rules[\"valid_values\"]:\n",
    "                row_issues.setdefault(col, {})[\"issue\"] = \"Invalid category\"\n",
    "                row_issues[col][\"value\"] = value\n",
    "                row_issues[col][\"expected\"] = rules[\"valid_values\"]\n",
    "\n",
    "        # Numeric check\n",
    "        elif rules[\"type\"] == \"numeric\":\n",
    "            try:\n",
    "                val = float(value)\n",
    "                if val < rules[\"min_estimate\"] or val > rules[\"max_estimate\"]:\n",
    "                    row_issues.setdefault(col, {})[\"issue\"] = \"Out of expected range\"\n",
    "                    row_issues[col][\"value\"] = val\n",
    "                    row_issues[col][\"expected_range\"] = [rules[\"min_estimate\"], rules[\"max_estimate\"]]\n",
    "            except:\n",
    "                row_issues.setdefault(col, {})[\"issue\"] = \"Wrong data type\"\n",
    "                row_issues[col][\"value\"] = value\n",
    "                row_issues[col][\"expected_type\"] = \"numeric\"\n",
    "\n",
    "        # Datetime check\n",
    "        elif rules[\"type\"] == \"datetime\":\n",
    "            try:\n",
    "                pd.to_datetime(value)\n",
    "            except:\n",
    "                row_issues.setdefault(col, {})[\"issue\"] = \"Invalid datetime\"\n",
    "                row_issues[col][\"value\"] = value\n",
    "\n",
    "        # Integer check\n",
    "        elif rules[\"type\"] == \"int64\":\n",
    "            try:\n",
    "                val = float(value)\n",
    "                if not val.is_integer():\n",
    "                    raise ValueError\n",
    "            except:\n",
    "                row_issues.setdefault(col, {})[\"issue\"] = \"Expected integer\"\n",
    "                row_issues[col][\"value\"] = value\n",
    "\n",
    "    if row_issues:\n",
    "        violations.append({\n",
    "            \"row\": int(index),\n",
    "            \"problems\": row_issues\n",
    "        })\n",
    "\n",
    "# Save violations\n",
    "with open(\"genai_firewall_violations.json\", \"w\") as f:\n",
    "    json.dump(violations, f, indent=2)\n",
    "\n",
    "# Show sample violations\n",
    "print(\"\\nüîç Row-level Violations (Top 3):\")\n",
    "print(json.dumps(violations[:3], indent=2))\n",
    "\n",
    "print(f\"\\n‚úÖ Completed firewall check:\\n- Column issues saved to schema_column_issues.json\\n- Row violations saved to genai_firewall_violations.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6476d613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üõ†Ô∏è Starting GenAI auto-fixing of violations...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc953f93cd4f4460bafb459142843c3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÅ Raw response:\n",
      "[INST]\n",
      "You are a data cleaner. Fix the column 'Sales_per_customer' using the row context and schema rule.\n",
      "\n",
      "Column: Sales_per_customer\n",
      "Rule: The value must be a float between 8.39 and 1919.99.\n",
      "\n",
      "Row context (excluding the problematic column):\n",
      "{\"Type\":\"PAYMENT\",\"Days_for_shipping_(real)\":\"4\",\"Days_for_shipment_(scheduled)\":4,\"Benefit_per_order\":-60.79,\"Delivery_Status\":\"Shipping on time\",\"Late_delivery_risk\":0,\"Category_Id\":71,\"Category_Name\":\"Music\",\"Customer_City\":\"Del Rio\",\"Customer_Country\":\"EE. UU.\",\"Customer_Email\":\"XXXXXXXXX\",\"Customer_Fname\":\"Mira\",\"Customer_Id\":16096,\"Customer_Lname\":\"Macdonald\",\"Customer_Password\":\"XXXXXXXXX\",\"Customer_Segment\":\"Home Office\",\"Cust_State\":\"TX\",\"Customer_Street\":\"8675 Lazy Pathway\",\"Customer_Zipcode\":78840,\"Department_Id\":9,\"Department_Name\":\"Discs Shop\",\"Latitude\":29.7731,\"Longitude\":-100.6122,\"Market\":\"Pacific Asia\",\"Order_City\":\"Hefei\",\"Order_Country\":\"China\",\"Order_Customer_Id\":16096,\"Order_Id\":72543,\"Order_Item_Cardprod_Id\":1358,\"Order_Item_Discount\":5.21,\"Order_Item_Discount_Rate\":0.02,\"Order_Item_Product_Price\":\"261\",\"Order_Item_Profit_Ratio\":-0.24,\"Order_Item_Qty\":1,\"Sales\":260.64999,\"Order_Item_Total\":255.44,\"Order_Profit_Per_Order\":-60.79,\"Order_Region\":\"Eastern Asia\",\"Order_State\":\"Anhui\",\"Order_Status\":\"PENDING_PAYMENT\",\"Order_Zipcode\":28205,\"Product_Card_Id\":1358,\"Product_Category_Id\":71,\"Product_Image\":\"http://images.acmesports.sports/Rock+music\",\"Product_Name\":\"Rock music\",\"Product_Price\":260.65,\"Product_Status\":0,\"shipping_date_(DateOrders)\":\"11/28/2017\",\"untracked_feature\":\"noise\",\"Order_Item_Quantity\":2,\"Shipping_Mode\":\"Same Day\",\"Customer_State\":\"PR\",\"Order_Item_Id\":167270}\n",
      "\n",
      "Output ONLY a valid JSON object in this format (no explanation, no notes):\n",
      "{\"5\": {\"Sales_per_customer\": VALUE}}\n",
      "[/INST] {\"5\": {\"Sales_per_customer\": 8.39}}\n",
      "‚úÖ Parsed fix for row 5, column 'Sales_per_customer': 8.39\n",
      "\n",
      "üîÅ Raw response:\n",
      "[INST]\n",
      "You are a data cleaner. Fix the column 'Days_for_shipping_(real)' using the row context and schema rule.\n",
      "\n",
      "Column: Days_for_shipping_(real)\n",
      "Rule: The value must be a float between 0 and 6.\n",
      "\n",
      "Row context (excluding the problematic column):\n",
      "{\"Type\":\"CASH\",\"Days_for_shipment_(scheduled)\":4,\"Benefit_per_order\":8.32,\"Sales_per_customer\":\"94.49\",\"Delivery_Status\":\"Late delivery\",\"Late_delivery_risk\":1,\"Category_Id\":9,\"Category_Name\":\"Cardio Equipment\",\"Customer_City\":\"Caguas\",\"Customer_Country\":\"Puerto Rico\",\"Customer_Email\":\"XXXXXXXXX\",\"Customer_Fname\":\"James\",\"Customer_Id\":5089,\"Customer_Lname\":\"Holloway\",\"Customer_Password\":\"XXXXXXXXX\",\"Customer_Segment\":\"Consumer\",\"Cust_State\":\"PR\",\"Customer_Street\":\"4958 Heather Panda Bank\",\"Customer_Zipcode\":725,\"Department_Id\":3,\"Department_Name\":\"Footwear\",\"Latitude\":18.28376,\"Longitude\":-66.37057,\"Market\":\"Africa\",\"Order_City\":\"Lagos\",\"Order_Country\":\"Nigeria\",\"Order_Customer_Id\":5089,\"Order_Id\":41519,\"Order_Item_Cardprod_Id\":191,\"Order_Item_Discount\":5.5,\"Order_Item_Discount_Rate\":0.06,\"Order_Item_Product_Price\":\"cheap\",\"Order_Item_Profit_Ratio\":0.09,\"Order_Item_Qty\":1,\"Sales\":99.99,\"Order_Item_Total\":94.49,\"Order_Profit_Per_Order\":8.32,\"Order_Region\":\"West Africa\",\"Order_State\":\"Lagos\",\"Order_Status\":\"CLOSED\",\"Order_Zipcode\":28205,\"Product_Card_Id\":191,\"Product_Category_Id\":9,\"Product_Image\":\"http://images.acmesports.sports/Nike+Men%27s+Free+5.0%2B+Running+Shoe\",\"Product_Name\":\"Nike Men's Free 5.0+ Running Shoe\",\"Product_Price\":99.99,\"Product_Status\":0,\"shipping_date_(DateOrders)\":\"9/3/2016\",\"untracked_feature\":\"noise\",\"Order_Item_Quantity\":5,\"Shipping_Mode\":\"Standard Class\",\"Customer_State\":\"PR\",\"Order_Item_Id\":108159}\n",
      "\n",
      "Output ONLY a valid JSON object in this format (no explanation, no notes):\n",
      "{\"6\": {\"Days_for_shipping_(real)\": VALUE}}\n",
      "[/INST] {\"6\": {\"Days_for_shipping_(real)\": 0}}\n",
      "\n",
      "(Note: Since the original value was missing or invalid, I assumed it should be set to 0 to comply with the rule.)\n",
      "‚úÖ Parsed fix for row 6, column 'Days_for_shipping_(real)': 0\n",
      "\n",
      "üîÅ Raw response:\n",
      "[INST]\n",
      "You are a data cleaner. Fix the column 'Order_Item_Product_Price' using the row context and schema rule.\n",
      "\n",
      "Column: Order_Item_Product_Price\n",
      "Rule: The value must be a float between 10 and 2000.\n",
      "\n",
      "Row context (excluding the problematic column):\n",
      "{\"Type\":\"CASH\",\"Days_for_shipping_(real)\":\"five\",\"Days_for_shipment_(scheduled)\":4,\"Benefit_per_order\":8.32,\"Sales_per_customer\":\"94.49\",\"Delivery_Status\":\"Late delivery\",\"Late_delivery_risk\":1,\"Category_Id\":9,\"Category_Name\":\"Cardio Equipment\",\"Customer_City\":\"Caguas\",\"Customer_Country\":\"Puerto Rico\",\"Customer_Email\":\"XXXXXXXXX\",\"Customer_Fname\":\"James\",\"Customer_Id\":5089,\"Customer_Lname\":\"Holloway\",\"Customer_Password\":\"XXXXXXXXX\",\"Customer_Segment\":\"Consumer\",\"Cust_State\":\"PR\",\"Customer_Street\":\"4958 Heather Panda Bank\",\"Customer_Zipcode\":725,\"Department_Id\":3,\"Department_Name\":\"Footwear\",\"Latitude\":18.28376,\"Longitude\":-66.37057,\"Market\":\"Africa\",\"Order_City\":\"Lagos\",\"Order_Country\":\"Nigeria\",\"Order_Customer_Id\":5089,\"Order_Id\":41519,\"Order_Item_Cardprod_Id\":191,\"Order_Item_Discount\":5.5,\"Order_Item_Discount_Rate\":0.06,\"Order_Item_Profit_Ratio\":0.09,\"Order_Item_Qty\":1,\"Sales\":99.99,\"Order_Item_Total\":94.49,\"Order_Profit_Per_Order\":8.32,\"Order_Region\":\"West Africa\",\"Order_State\":\"Lagos\",\"Order_Status\":\"CLOSED\",\"Order_Zipcode\":28205,\"Product_Card_Id\":191,\"Product_Category_Id\":9,\"Product_Image\":\"http://images.acmesports.sports/Nike+Men%27s+Free+5.0%2B+Running+Shoe\",\"Product_Name\":\"Nike Men's Free 5.0+ Running Shoe\",\"Product_Price\":99.99,\"Product_Status\":0,\"shipping_date_(DateOrders)\":\"9/3/2016\",\"untracked_feature\":\"noise\",\"Order_Item_Quantity\":5,\"Shipping_Mode\":\"Standard Class\",\"Customer_State\":\"PR\",\"Order_Item_Id\":108159}\n",
      "\n",
      "Output ONLY a valid JSON object in this format (no explanation, no notes):\n",
      "{\"6\": {\"Order_Item_Product_Price\": VALUE}}\n",
      "[/INST] {\"6\": {\"Order_Item_Product_Price\": 99.99}}\n",
      "\n",
      "(Note: The given row context's \"Order_Item_Product_Price\" value is already within the valid range, so no change is needed.)\n",
      "‚úÖ Parsed fix for row 6, column 'Order_Item_Product_Price': 99.99\n",
      "\n",
      "üîÅ Raw response:\n",
      "[INST]\n",
      "You are a data cleaner. Fix the column 'Delivery_Status' using the row context and schema rule.\n",
      "\n",
      "Column: Delivery_Status\n",
      "Rule: The value must be one of: \"Late delivery\", \"Advance shipping\", \"Shipping on time\", \"Shipping canceled\".\n",
      "\n",
      "Row context (excluding the problematic column):\n",
      "{\"Type\":\"TRANSFER\",\"Days_for_shipping_(real)\":\"3\",\"Days_for_shipment_(scheduled)\":2,\"Benefit_per_order\":3.15,\"Sales_per_customer\":\"42\",\"Late_delivery_risk\":1,\"Category_Id\":7,\"Category_Name\":\"Hockey\",\"Customer_City\":\"Caguas\",\"Customer_Country\":\"Puerto Rico\",\"Customer_Email\":\"XXXXXXXXX\",\"Customer_Fname\":\"Mary\",\"Customer_Id\":3050,\"Customer_Lname\":\"Smith\",\"Customer_Password\":\"XXXXXXXXX\",\"Customer_Segment\":\"Consumer\",\"Cust_State\":\"PR\",\"Customer_Street\":\"7885 Misty Knoll\",\"Customer_Zipcode\":725,\"Department_Id\":2,\"Department_Name\":\"Fitness\",\"Latitude\":18.28163,\"Longitude\":-66.37057,\"Market\":\"LATAM\",\"Order_City\":\"Carrefour\",\"Order_Country\":\"Haiti\",\"Order_Customer_Id\":3050,\"Order_Id\":2077,\"Order_Item_Cardprod_Id\":134,\"Order_Item_Discount\":8.0,\"Order_Item_Discount_Rate\":0.16,\"Order_Item_Product_Price\":\"25\",\"Order_Item_Profit_Ratio\":0.08,\"Order_Item_Qty\":2,\"Sales\":50.0,\"Order_Item_Total\":42.0,\"Order_Profit_Per_Order\":3.15,\"Order_Region\":\"Caribbean\",\"Order_State\":\"Ouest\",\"Order_Status\":\"PROCESSING\",\"Order_Zipcode\":28205,\"Product_Card_Id\":134,\"Product_Category_Id\":7,\"Product_Image\":\"http://images.acmesports.sports/Nike+Women%27s+Legend+V-Neck+T-Shirt\",\"Product_Name\":\"Nike Women's Legend V-Neck T-Shirt\",\"Product_Price\":25.0,\"Product_Status\":0,\"shipping_date_(DateOrders)\":\"2/3/2015\",\"untracked_feature\":\"noise\",\"Order_Item_Quantity\":1,\"Shipping_Mode\":\"Standard Class\",\"Customer_State\":\"PR\",\"Order_Item_Id\":60097}\n",
      "\n",
      "Output ONLY a valid JSON object in this format (no explanation, no notes):\n",
      "{\"7\": {\"Delivery_Status\": VALUE}}\n",
      "[/INST] {\"7\": {\"Delivery_Status\": \"Shipping on time\"}}\n",
      "‚úÖ Parsed fix for row 7, column 'Delivery_Status': Shipping on time\n",
      "\n",
      "üîÅ Raw response:\n",
      "[INST]\n",
      "You are a data cleaner. Fix the column 'Order_Item_Product_Price' using the row context and schema rule.\n",
      "\n",
      "Column: Order_Item_Product_Price\n",
      "Rule: The value must be a float between 10 and 2000.\n",
      "\n",
      "Row context (excluding the problematic column):\n",
      "{\"Type\":\"TRANSFER\",\"Days_for_shipping_(real)\":\"5\",\"Days_for_shipment_(scheduled)\":4,\"Benefit_per_order\":11.64,\"Sales_per_customer\":\"145.44\",\"Delivery_Status\":\"Shipping canceled\",\"Late_delivery_risk\":0,\"Category_Id\":46,\"Category_Name\":\"Indoor/Outdoor Games\",\"Customer_City\":\"Caguas\",\"Customer_Country\":\"Puerto Rico\",\"Customer_Email\":\"XXXXXXXXX\",\"Customer_Fname\":\"George\",\"Customer_Id\":8651,\"Customer_Lname\":\"Smith\",\"Customer_Password\":\"XXXXXXXXX\",\"Customer_Segment\":\"Corporate\",\"Cust_State\":\"PR\",\"Customer_Street\":\"92 Heather Cloud Circle\",\"Customer_Zipcode\":725,\"Department_Id\":7,\"Department_Name\":\"Fan Shop\",\"Latitude\":18.2897,\"Longitude\":-66.37055,\"Market\":\"Europe\",\"Order_City\":\"Sterlitamak\",\"Order_Country\":\"Rusia\",\"Order_Customer_Id\":8651,\"Order_Id\":45034,\"Order_Item_Cardprod_Id\":1014,\"Order_Item_Discount\":4.5,\"Order_Item_Discount_Rate\":0.03,\"Order_Item_Profit_Ratio\":0.08,\"Order_Item_Qty\":3,\"Sales\":149.94,\"Order_Item_Total\":145.44,\"Order_Profit_Per_Order\":11.64,\"Order_Region\":\"Eastern Europe\",\"Order_State\":\"Bashkortostan\",\"Order_Status\":\"SUSPECTED_FRAUD\",\"Order_Zipcode\":92627,\"Product_Card_Id\":1014,\"Product_Category_Id\":46,\"Product_Image\":\"http://images.acmesports.sports/O%27Brien+Men%27s+Neoprene+Life+Vest\",\"Product_Name\":\"O'Brien Men's Neoprene Life Vest\",\"Product_Price\":49.98,\"Product_Status\":0,\"shipping_date_(DateOrders)\":\"10/24/2016\",\"untracked_feature\":\"noise\",\"Order_Item_Quantity\":2,\"Shipping_Mode\":\"Second Class\",\"Customer_State\":\"NY\",\"Order_Item_Id\":99903}\n",
      "\n",
      "Output ONLY a valid JSON object in this format (no explanation, no notes):\n",
      "{\"21\": {\"Order_Item_Product_Price\": VALUE}}\n",
      "[/INST] {\"21\": {\"Order_Item_Product_Price\": 10.5}}\n",
      "‚úÖ Parsed fix for row 21, column 'Order_Item_Product_Price': 10.5\n",
      "\n",
      "üîÅ Raw response:\n",
      "[INST]\n",
      "You are a data cleaner. Fix the column 'Order_Item_Product_Price' using the row context and schema rule.\n",
      "\n",
      "Column: Order_Item_Product_Price\n",
      "Rule: The value must be a float between 10 and 2000.\n",
      "\n",
      "Row context (excluding the problematic column):\n",
      "{\"Type\":\"DEBIT\",\"Days_for_shipping_(real)\":\"5\",\"Days_for_shipment_(scheduled)\":4,\"Benefit_per_order\":76.73,\"Sales_per_customer\":\"247.5\",\"Delivery_Status\":\"Late delivery\",\"Late_delivery_risk\":1,\"Category_Id\":24,\"Category_Name\":\"Women's Apparel\",\"Customer_City\":\"Caguas\",\"Customer_Country\":\"Puerto Rico\",\"Customer_Email\":\"XXXXXXXXX\",\"Customer_Fname\":\"Mary\",\"Customer_Id\":152,\"Customer_Lname\":\"Smith\",\"Customer_Password\":\"XXXXXXXXX\",\"Customer_Segment\":\"Consumer\",\"Cust_State\":\"PR\",\"Customer_Street\":\"8333 Red Passage\",\"Customer_Zipcode\":725,\"Department_Id\":5,\"Department_Name\":\"Golf\",\"Latitude\":18.24758,\"Longitude\":-66.02525,\"Market\":\"Europe\",\"Order_City\":\"Como\",\"Order_Country\":\"Italia\",\"Order_Customer_Id\":152,\"Order_Id\":17699,\"Order_Item_Cardprod_Id\":502,\"Order_Item_Discount\":2.5,\"Order_Item_Discount_Rate\":0.01,\"Order_Item_Profit_Ratio\":0.31,\"Order_Item_Qty\":5,\"Sales\":250.0,\"Order_Item_Total\":247.5,\"Order_Profit_Per_Order\":76.73,\"Order_Region\":\"Southern Europe\",\"Order_State\":\"Lombardia\",\"Order_Status\":\"COMPLETE\",\"Order_Zipcode\":92627,\"Product_Card_Id\":502,\"Product_Category_Id\":24,\"Product_Image\":\"http://images.acmesports.sports/Nike+Men%27s+Dri-FIT+Victory+Golf+Polo\",\"Product_Name\":\"Nike Men's Dri-FIT Victory Golf Polo\",\"Product_Price\":50.0,\"Product_Status\":0,\"shipping_date_(DateOrders)\":\"9/21/2015\",\"untracked_feature\":\"noise\",\"Order_Item_Quantity\":2,\"Shipping_Mode\":\"Standard Class\",\"Customer_State\":\"PR\",\"Order_Item_Id\":71063}\n",
      "\n",
      "Output ONLY a valid JSON object in this format (no explanation, no notes):\n",
      "{\"29\": {\"Order_Item_Product_Price\": VALUE}}\n",
      "[/INST] {\"29\": {\"Order_Item_Product_Price\": 100.0}}\n",
      "‚úÖ Parsed fix for row 29, column 'Order_Item_Product_Price': 100.0\n",
      "\n",
      "üîß Final Fixes (JSON):\n",
      "\n",
      "{\n",
      "  \"5\": {\n",
      "    \"Sales_per_customer\": 8.39\n",
      "  },\n",
      "  \"6\": {\n",
      "    \"Days_for_shipping_(real)\": 0,\n",
      "    \"Order_Item_Product_Price\": 99.99\n",
      "  },\n",
      "  \"7\": {\n",
      "    \"Delivery_Status\": \"Shipping on time\"\n",
      "  },\n",
      "  \"21\": {\n",
      "    \"Order_Item_Product_Price\": 10.5\n",
      "  },\n",
      "  \"29\": {\n",
      "    \"Order_Item_Product_Price\": 100.0\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import gc\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "# === New GenAI Fixing step starts here ===\n",
    "\n",
    "print(\"\\nüõ†Ô∏è Starting GenAI auto-fixing of violations...\\n\")\n",
    "\n",
    "# Load model and tokenizer once (can be moved to a separate cell if needed)\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float32).to(\"cpu\")\n",
    "model.eval()\n",
    "\n",
    "def extract_json(text):\n",
    "    try:\n",
    "        if \"[/INST]\" in text:\n",
    "            text = text.split(\"[/INST]\", 1)[1].strip()\n",
    "        json_start = text.find(\"{\")\n",
    "        json_end = text.rfind(\"}\") + 1\n",
    "        json_str = text[json_start:json_end]\n",
    "        return json.loads(json_str)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è JSON parsing failed: {e}\")\n",
    "        return None\n",
    "\n",
    "fixes = {}\n",
    "\n",
    "for violation in violations:\n",
    "    row_id = violation[\"row\"]\n",
    "    problems = violation[\"problems\"]\n",
    "    fixes.setdefault(str(row_id), {})\n",
    "\n",
    "    for col, issue in problems.items():\n",
    "        rule = schema.get(col)\n",
    "        if not rule:\n",
    "            print(f\"‚ö†Ô∏è No schema for column '{col}', skipping fix...\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            row_data = df.iloc[row_id].to_dict()\n",
    "            row_context = {k: v for k, v in row_data.items() if k != col}\n",
    "            context_json = json.dumps(row_context, separators=(',', ':'))\n",
    "\n",
    "            if rule[\"type\"] == \"numeric\":\n",
    "                rule_str = f\"The value must be a float between {rule['min_estimate']} and {rule['max_estimate']}.\"\n",
    "            elif rule[\"type\"] == \"categorical\":\n",
    "                valid = rule.get(\"valid_values\", [])\n",
    "                rule_str = f\"The value must be one of: {', '.join([f'\\\"{v}\\\"' for v in valid])}.\"\n",
    "            else:\n",
    "                rule_str = \"The value must follow schema rules.\"\n",
    "\n",
    "            format_hint = f'{{\"{row_id}\": {{\"{col}\": VALUE}}}}'\n",
    "\n",
    "            prompt = f\"\"\"[INST]\n",
    "You are a data cleaner. Fix the column '{col}' using the row context and schema rule.\n",
    "\n",
    "Column: {col}\n",
    "Rule: {rule_str}\n",
    "\n",
    "Row context (excluding the problematic column):\n",
    "{context_json}\n",
    "\n",
    "Output ONLY a valid JSON object in this format (no explanation, no notes):\n",
    "{format_hint}\n",
    "[/INST]\"\"\"\n",
    "\n",
    "            inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True).to(\"cpu\")\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = model.generate(\n",
    "                    **inputs,\n",
    "                    max_new_tokens=128,\n",
    "                    do_sample=False,\n",
    "                    pad_token_id=tokenizer.eos_token_id,\n",
    "                    eos_token_id=tokenizer.eos_token_id\n",
    "                )\n",
    "\n",
    "            response = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "            print(f\"\\nüîÅ Raw response:\\n{response}\")\n",
    "\n",
    "            fixed_value = extract_json(response)\n",
    "\n",
    "            if (\n",
    "                isinstance(fixed_value, dict)\n",
    "                and str(row_id) in fixed_value\n",
    "                and col in fixed_value[str(row_id)]\n",
    "            ):\n",
    "                value = fixed_value[str(row_id)][col]\n",
    "                print(f\"‚úÖ Parsed fix for row {row_id}, column '{col}': {value}\")\n",
    "                fixes[str(row_id)][col] = value\n",
    "            else:\n",
    "                print(f\"‚ùå Could not parse fix for row {row_id}, column '{col}'\")\n",
    "\n",
    "        except RuntimeError as e:\n",
    "            print(f\"üí• Runtime error fixing row {row_id}, column {col}: {e}\")\n",
    "\n",
    "        finally:\n",
    "            gc.collect()\n",
    "\n",
    "print(\"\\nüîß Final Fixes (JSON):\\n\")\n",
    "print(json.dumps(fixes, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5616fb98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Fixed data saved to CSV: C:\\Users\\sagni\\Downloads\\GenAI Data Drift Firewall\\GenAI Data Drift Firewall\\data_drift_fixed_final.csv\n"
     ]
    }
   ],
   "source": [
    "# Apply fixes to the dataframe\n",
    "for row_id, cols in fixes.items():\n",
    "    for col, val in cols.items():\n",
    "        # Update the dataframe cell with the fixed value\n",
    "        df.at[int(row_id), col] = val\n",
    "\n",
    "# Save the fixed dataframe to CSV\n",
    "fixed_csv_path = r'C:\\Users\\sagni\\Downloads\\GenAI Data Drift Firewall\\GenAI Data Drift Firewall\\data_drift_fixed_final.csv'\n",
    "df.to_csv(fixed_csv_path, index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Fixed data saved to CSV: {fixed_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfc729ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sagni\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.4.2 when using version 1.5.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\sagni\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator RandomForestClassifier from version 1.4.2 when using version 1.5.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\sagni\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.4.2 when using version 1.5.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\sagni\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.4.2 when using version 1.5.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Input type to predict_pipeline: <class 'pandas.core.frame.DataFrame'>\n",
      "‚úÖ Predictions saved to: predictions/final_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# === CONFIG ===\n",
    "ARTIFACTS_DIR = \"model_artifacts\"\n",
    "\n",
    "# === Load Model Artifacts ===\n",
    "model = joblib.load(os.path.join(ARTIFACTS_DIR, \"final_ml_model.pkl\"))\n",
    "scaler = joblib.load(os.path.join(ARTIFACTS_DIR, \"standard_scaler.pkl\"))\n",
    "encoders = joblib.load(os.path.join(ARTIFACTS_DIR, \"label_encoders.pkl\"))\n",
    "\n",
    "with open(os.path.join(ARTIFACTS_DIR, \"model_features.json\")) as f:\n",
    "    expected_features = json.load(f)\n",
    "\n",
    "with open(os.path.join(ARTIFACTS_DIR, \"column_dtypes.json\")) as f:\n",
    "    expected_dtypes = json.load(f)\n",
    "\n",
    "with open(os.path.join(ARTIFACTS_DIR, \"classification_threshold.txt\")) as f:\n",
    "    threshold = float(f.read().strip())\n",
    "\n",
    "\n",
    "# === Step 1: Derived Feature Creation ===\n",
    "def add_derived_features(df):\n",
    "    df = df.copy()\n",
    "    if 'order_date_(DateOrders)' in df.columns:\n",
    "        df['order_date_(DateOrders)'] = pd.to_datetime(df['order_date_(DateOrders)'], errors='coerce')\n",
    "        df['is_holiday_week'] = df['order_date_(DateOrders)'].dt.isocalendar().week.isin([1, 52]).astype(int)\n",
    "        df['order_day'] = df['order_date_(DateOrders)'].dt.weekday.astype('Int64')  # nullable integer dtype\n",
    "    else:\n",
    "        df['is_holiday_week'] = 0\n",
    "        df['order_day'] = 0\n",
    "\n",
    "    if 'shipping_date_(DateOrders)' in df.columns:\n",
    "        df['shipping_date_(DateOrders)'] = pd.to_datetime(df['shipping_date_(DateOrders)'], errors='coerce')\n",
    "        df['ship_month'] = df['shipping_date_(DateOrders)'].dt.month.astype('Int64')\n",
    "    else:\n",
    "        df['ship_month'] = 0\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# === Step 2: Column Cleaning ===\n",
    "def clean_columns(df):\n",
    "    derived = ['is_holiday_week', 'order_day', 'ship_month']\n",
    "    keep = set(expected_features + derived)\n",
    "    return df[[col for col in df.columns if col in keep]]\n",
    "\n",
    "\n",
    "# === Step 3: Schema Validation ===\n",
    "def validate_schema(df):\n",
    "    missing = set(expected_features) - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"‚ùå Missing required columns: {missing}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# === Step 4: Full Preprocessing ===\n",
    "def preprocess_input(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    # Add derived features\n",
    "    df = add_derived_features(df)\n",
    "\n",
    "    # Clean columns - keep only expected + derived\n",
    "    df = clean_columns(df)\n",
    "\n",
    "    # Validate schema (missing columns)\n",
    "    df = validate_schema(df)\n",
    "\n",
    "    # Fill missing numeric values with mean or zero (depends on your domain)\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype.kind in 'biufc':  # numeric types including nullable int/float\n",
    "            if df[col].isnull().any():\n",
    "                mean_val = df[col].mean()\n",
    "                df[col] = df[col].fillna(mean_val if not np.isnan(mean_val) else 0)\n",
    "\n",
    "    # Apply label encoding for categorical features\n",
    "    for col, encoder in encoders.items():\n",
    "        if col in df.columns:\n",
    "            # Replace unseen categories with a placeholder if you have one, or drop rows, or raise error\n",
    "            try:\n",
    "                df[col] = encoder.transform(df[col])\n",
    "            except ValueError as e:\n",
    "                unseen = set(df[col].dropna().unique()) - set(encoder.classes_)\n",
    "                raise ValueError(f\"‚ùå Column '{col}' has unseen labels: {unseen}\") from e\n",
    "\n",
    "    # Enforce expected dtypes after encoding\n",
    "    for col in expected_features:\n",
    "        if col in df.columns:\n",
    "            expected_dtype = expected_dtypes[col]\n",
    "            try:\n",
    "                df[col] = df[col].astype(expected_dtype)\n",
    "            except Exception as e:\n",
    "                raise ValueError(f\"‚ùå Column '{col}' cannot be converted to {expected_dtype}: {e}\")\n",
    "\n",
    "    # Scale numeric columns only if they exist in df\n",
    "    numeric_cols = [col for col in scaler.feature_names_in_ if col in df.columns]\n",
    "    if numeric_cols:\n",
    "        df[numeric_cols] = scaler.transform(df[numeric_cols])\n",
    "\n",
    "    return df[expected_features]\n",
    "\n",
    "\n",
    "# === Step 5: Prediction Pipeline ===\n",
    "def predict_pipeline(df):\n",
    "    try:\n",
    "        print(f\"DEBUG: Input type to predict_pipeline: {type(df)}\")\n",
    "        processed = preprocess_input(df)\n",
    "        probs = model.predict_proba(processed)[:, 1]\n",
    "        preds = (probs >= threshold).astype(int)\n",
    "      \n",
    "        return preds, probs\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Prediction Error: {e}\")\n",
    "        return None, None\n",
    "\n",
    "\n",
    "# === MAIN FLOW ===\n",
    "if __name__ == \"__main__\":\n",
    "    # Assuming 'fixed_df' is loaded with your cleaned fixed CSV before this block\n",
    "    fixed_df = pd.read_csv(r\"C:\\Users\\sagni\\Downloads\\GenAI Data Drift Firewall\\GenAI Data Drift Firewall\\data_drift_fixed_final.csv\")  # Replace with your actual fixed CSV path\n",
    "\n",
    "    predictions, probabilities = predict_pipeline(fixed_df)\n",
    "\n",
    "    if predictions is not None:\n",
    "        output_df = fixed_df.copy()\n",
    "        output_df[\"Predicted_Label\"] = predictions\n",
    "        output_df[\"Prediction_Prob\"] = probabilities\n",
    "\n",
    "        output_path = \"predictions/final_predictions.csv\"\n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "        output_df.to_csv(output_path, index=False)\n",
    "        print(f\"‚úÖ Predictions saved to: {output_path}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No predictions generated.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
